{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# emData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./emData.csv', sep=',',encoding='windows-1252')\n",
    "data.sample(5)\n",
    "atUser = \"\"\n",
    "Links = \"\"\n",
    "data['atUser'] = atUser\n",
    "data['Links'] = Links\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        True\n",
      "1        True\n",
      "2        True\n",
      "3       False\n",
      "4       False\n",
      "        ...  \n",
      "3213     True\n",
      "3214    False\n",
      "3215    False\n",
      "3216    False\n",
      "3217     True\n",
      "Name: Tweet, Length: 3218, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "print(data.Tweet.str.contains(\"@\"))\n",
    "at_user_regex = r'@\\w+'\n",
    "link_regex = r'https://\\S+'\n",
    "data['atUser'] = data.Tweet.str.findall(at_user_regex)\n",
    "data['Links']= data.Tweet.str.findall(link_regex)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('emData_processed.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tsla_reddit_comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_sentiment_score(value):\n",
    "    if pd.isnull(value):\n",
    "        return 0\n",
    "    elif value > 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return -1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = pd.read_csv('./tsla_reddit.csv', sep=',')\n",
    "data2.shape\n",
    "data2 = data2.drop(columns=[\"subreddit.id\",\"id\",\"type\",\"permalink\",\"created_utc\",\"subreddit.nsfw\"])\n",
    "data2 = data2.rename(columns={\"sentiment\": \"sentiment_score_range\"})\n",
    "data2[\"sentiment_score\"] = data2[\"sentiment_score_range\"].apply(map_sentiment_score)\n",
    "data2.sample(5)\n",
    "data3 = data2.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.to_csv('tsla_reddit_proccessed.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit.name</th>\n",
       "      <th>body</th>\n",
       "      <th>sentiment_score_range</th>\n",
       "      <th>score</th>\n",
       "      <th>sentiment_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>218102</th>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>You really have to go ballsdeep with tsla call...</td>\n",
       "      <td>-0.6249</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125356</th>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>holy shit the chart in tsla lmaooo</td>\n",
       "      <td>-0.5574</td>\n",
       "      <td>5</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146989</th>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>TsLa/apple red, googl/amzn almost red, fb not ...</td>\n",
       "      <td>-0.7043</td>\n",
       "      <td>6</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66481</th>\n",
       "      <td>tslalounge</td>\n",
       "      <td>I would dca into TSLA 100%, until the robotaxi...</td>\n",
       "      <td>0.3182</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14431</th>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>time for TSLA to drill to now shake out the calls</td>\n",
       "      <td>-0.1779</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        subreddit.name                                               body  \\\n",
       "218102  wallstreetbets  You really have to go ballsdeep with tsla call...   \n",
       "125356  wallstreetbets                 holy shit the chart in tsla lmaooo   \n",
       "146989  wallstreetbets  TsLa/apple red, googl/amzn almost red, fb not ...   \n",
       "66481       tslalounge  I would dca into TSLA 100%, until the robotaxi...   \n",
       "14431   wallstreetbets  time for TSLA to drill to now shake out the calls   \n",
       "\n",
       "        sentiment_score_range  score  sentiment_score  \n",
       "218102                -0.6249      1               -1  \n",
       "125356                -0.5574      5               -1  \n",
       "146989                -0.7043      6               -1  \n",
       "66481                  0.3182      7                1  \n",
       "14431                 -0.1779      1               -1  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data3\n",
    "Emoticons = pd.DataFrame({'positive':\n",
    "                          [\":)\",\":>\", \"(◕ᴥ◕)\", \"（〜 ^∇^ )〜\",\"( ͡ᵔ ͜ʖ ͡ᵔ )\",\"ʘ‿ʘ\",\"(•‿•)\",\"♡＾▽＾♡\",\"(♡´౪`♡)\",\"♡〜٩( ˃́▿˂̀ )۶〜♡\",\"ʘ‿ʘ\",\"(•‿•)\",\"♡＾▽＾♡\",\"(♡´౪`♡)\",\"♡〜٩( ˃́▿˂̀ )۶〜♡\",\":)\",\":>\", \"(◕ᴥ◕)\", \"（〜 ^∇^ )〜\",\"( ͡ᵔ ͜ʖ ͡ᵔ )\",\"ʘ‿ʘ\",\"(•‿•)\",\"♡＾▽＾♡\",\"(♡´౪`♡)\",\"♡〜٩( ˃́▿˂̀ )۶〜♡\",\"ʘ‿ʘ\",\"(•‿•)\",\"♡＾▽＾♡\",\"(♡´౪`♡)\",\"♡〜٩( ˃́▿˂̀ )۶〜♡\"],\n",
    "                          'negative':\n",
    "                          [\":<\",\":(\", \"(¬▂¬)\", \"(눈_눈)\",\"(｀д´)ゝ\",\"( p_q)\",\"(,Ծ_Ծ,)\",\"ᕙ(⇀‸↼‶) ᕗ\",\"୧( ˵ ° ~ ° ˵ )୨\",\"ᕕ༼•̀︿•́༽ᕗ\",\"( p_q)\",\"(,Ծ_Ծ,)\",\"ᕙ(⇀‸↼‶) ᕗ\",\"୧( ˵ ° ~ ° ˵ )୨\",\"ᕕ༼•̀︿•́༽ᕗ\",\":<\",\":(\", \"(¬▂¬)\", \"(눈_눈)\",\"(｀д´)ゝ\",\"( p_q)\",\"(,Ծ_Ծ,)\",\"ᕙ(⇀‸↼‶) ᕗ\",\"୧( ˵ ° ~ ° ˵ )୨\",\"ᕕ༼•̀︿•́༽ᕗ\",\"( p_q)\",\"(,Ծ_Ծ,)\",\"ᕙ(⇀‸↼‶) ᕗ\",\"୧( ˵ ° ~ ° ˵ )୨\",\"ᕕ༼•̀︿•́༽ᕗ\"],\n",
    "                          'neutral' :\n",
    "                          [\"ლ(・ヮ・ლ)\",\"⊂(・ヮ・⊂)\", \"(⊃‿⊂)\", \"|･x･`)\",\"｜。・）\",\"｢(◔ω◔「)三\",\"(̿▨-▨¬˵)(˘ε˘˶๑ )\",\"(ー_ーゞ\",\"（◎ー◎；）\",\"(¯―¯ ٥)\",\"｢(◔ω◔「)三\",\"(̿▨-▨¬˵)(˘ε˘˶๑ )\",\"(ー_ーゞ\",\"（◎ー◎；）\",\"(¯―¯ ٥)\",\"ლ(・ヮ・ლ)\",\"⊂(・ヮ・⊂)\", \"(⊃‿⊂)\", \"|･x･`)\",\"｜。・）\",\"｢(◔ω◔「)三\",\"(̿▨-▨¬˵)(˘ε˘˶๑ )\",\"(ー_ーゞ\",\"（◎ー◎；）\",\"(¯―¯ ٥)\",\"｢(◔ω◔「)三\",\"(̿▨-▨¬˵)(˘ε˘˶๑ )\",\"(ー_ーゞ\",\"（◎ー◎；）\",\"(¯―¯ ٥)\"],\n",
    "                          })\n",
    "Emoticons.at[9999, 'positive'] = \"d(✪‿✪)\"\n",
    "Emoticons.at[9999, 'negative'] = \"(▰˘︹˘▰)\"\n",
    "Emoticons.at[9999, 'neutral'] = \"ヾ( ‘ – ‘*)\"\n",
    "\n",
    "# print(Emoticons.sample(5))\n",
    "# data3.at[194237, 'body'] = \"Pretty typical TSLA bear.(♡´౪`♡)\"\n",
    "# data3.at[154256, 'body'] = \"ᕕ༼•̀︿•́༽ᕗ\"\n",
    "# # data3.at[89502, 'body'] = \":)\"\n",
    "# # data3.at[82198, 'body'] = \":)\"\n",
    "# # data3.at[138468, 'body'] = \":)\"\n",
    "# Emoticons.sample(5)\n",
    "# data3\n",
    "def check_emoticons(text, emoticons):\n",
    "    for emoticon in emoticons:\n",
    "        if emoticon in text:\n",
    "            return True\n",
    "    return False\n",
    "data3['positive_emoticon'] = data3['body'].apply(lambda x: check_emoticons(x, Emoticons.positive))\n",
    "data3['negative_emoticon'] = data3['body'].apply(lambda x: check_emoticons(x, Emoticons.negative))\n",
    "data3['neutral_emoticon'] = data3['body'].apply(lambda x: check_emoticons(x, Emoticons.neutral))\n",
    "\n",
    "data3.sample(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qsharp-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
